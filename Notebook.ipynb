{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Album Data from MusicBrainz Database\n",
    "\n",
    "Some imports first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import PyLyrics\n",
    "\n",
    "from sqlalchemy import (create_engine, MetaData, Table, Column, \n",
    "                        ForeignKey, select, func, Integer, text,\n",
    "                        String, distinct, bindparam)\n",
    "from sqlalchemy import exc as sa_exc\n",
    "from sqlalchemy.dialects.postgresql import ARRAY\n",
    "from sqlalchemy.ext import automap\n",
    "from sqlalchemy.orm import sessionmaker, class_mapper\n",
    "from sqlalchemy.sql.expression import label, case\n",
    "from sqlalchemy.sql import literal_column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some global settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_url = 'postgresql+psycopg2://musicbrainz@localhost:6543/musicbrainz'\n",
    "\n",
    "dump_filename = 'musicbrainz.json'\n",
    "lyrics_dir = 'lyrics'\n",
    "final_filename = 'musicbrainz-with-lyrics.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine(db_url)\n",
    "conn = engine.connect()\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflect the tables we need\n",
    "\n",
    "The two schemes used are _musicbrainz_ which is the default scheme, and _cover_art_archive_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tables = \"\"\"release_group release_group_primary_type release \n",
    "release_status release_country release_unknown_country release_packaging\n",
    "release_label label label_type artist artist_credit artist_credit_name \n",
    "artist_type gender area medium track country_area area\"\"\".split()\n",
    "\n",
    "ca_tables = \"cover_art cover_art_type\".split()\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=sa_exc.SAWarning)\n",
    "\n",
    "    meta = MetaData()\n",
    "    meta.reflect(bind=engine, only=tables)\n",
    "    Base = automap.automap_base(metadata=meta)\n",
    "    Base.prepare()\n",
    "    \n",
    "    ca_meta = MetaData(schema='cover_art_archive')\n",
    "    ca_meta.reflect(bind=engine, only=ca_tables) \n",
    "    CABase = automap.automap_base(metadata=ca_meta)\n",
    "    CABase.prepare()\n",
    "\n",
    "# only do this when it is ok to be lazy!\n",
    "loc = locals()\n",
    "\n",
    "camelize = lambda s: s[0].upper() + \\\n",
    "    re.sub(r'_([a-z])', lambda m: m.group(1).upper(), s[1:])\n",
    "\n",
    "for table in tables:\n",
    "    loc[camelize(table)] = getattr(Base.classes, table)\n",
    "    \n",
    "for table in ca_tables:\n",
    "    loc[camelize(table)] = getattr(CABase.classes, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's have a look at the MusicBrainz database:\n",
    "\n",
    "Hint:\n",
    "* The _release_group_ is the abstract Album (exampel Jimi Hendrix - Electric Ladyland)\n",
    "* A _release_ is a physical (or digital, nowadays) Album with a bar code, maybe some country specific songs on it, etc.\n",
    "\n",
    "![Musicbrainz Schema](https://wiki.musicbrainz.org/-/images/5/52/ngs.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two subqueries\n",
    "\n",
    "First we find the original release date/year by creation a union table of _release_country_ and _release_unknown_country_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Union of ReleaseCountry and ReleaseUnknownCountry\n",
    "q1 = session.query(\n",
    "    label('release', ReleaseCountry.release), \n",
    "    label('date_year', ReleaseCountry.date_year),\n",
    "    label('date', case([(ReleaseCountry.date_year == None, None)], else_=func.concat(\n",
    "        ReleaseCountry.date_year, '-', \n",
    "        text(\"COALESCE(LPAD(date_month::text, 2, '0'), '12')\"), '-', \n",
    "        text(\"COALESCE(LPAD(date_day::text, 2, '0'), '12')\"))\n",
    "    )),\n",
    ")\n",
    "\n",
    "q2 = session.query(\n",
    "    label('release', ReleaseUnknownCountry.release),\n",
    "    label('date_year', ReleaseUnknownCountry.date_year),\n",
    "    label('date', case([(ReleaseUnknownCountry.date_year == None, None)], else_=func.concat(\n",
    "        ReleaseUnknownCountry.date_year, '-', \n",
    "        text(\"COALESCE(LPAD(date_month::text, 2, '0'), '12')\"), '-', \n",
    "        text(\"COALESCE(LPAD(date_day::text, 2, '0'), '12')\"))\n",
    "    )),\n",
    ")\n",
    "\n",
    "ReleaseDate = q1.union_all(q2).subquery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the packaging, we want an array containing all the different packaging for a given release_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate all packagings available in a release_group\n",
    "Packaging = session.query(\n",
    "    Release.release_group.label('release_group'),\n",
    "    func.array_agg(distinct(ReleasePackaging.name), type_=ARRAY(String, as_tuple=True))\\\n",
    "        .label('packaging'),\n",
    "   \n",
    ")\n",
    "Packaging = Packaging.join(ReleasePackaging, Release.packaging == ReleasePackaging.id)\n",
    "Packaging = Packaging.group_by(Release.release_group)\n",
    "Packaging = Packaging.subquery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main query\n",
    "\n",
    "First the list with all the values we want to fetch from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = session.query(\n",
    "        Release.id, \n",
    "        Release.gid, \n",
    "        Release.name, \n",
    "        Release.release_group, \n",
    "        ReleaseGroupPrimaryType.name,\n",
    "        ReleaseDate.c.date_year,\n",
    "        ReleaseDate.c.date, \n",
    "        ArtistCredit.name, \n",
    "        Artist.name, \n",
    "        Artist.begin_date_year,\n",
    "        Artist.end_date_year,\n",
    "        Gender.name,\n",
    "        ArtistType.name,\n",
    "        Packaging.c.packaging,\n",
    "        Label.name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are a lot of tables to join. Some are inner, some outer joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = q.join(ReleaseGroup, Release.release_group == ReleaseGroup.id)\n",
    "q = q.outerjoin(ReleaseGroupPrimaryType, ReleaseGroupPrimaryType.id == ReleaseGroup.type)\n",
    "q = q.join(ArtistCredit, Release.artist_credit == ArtistCredit.id)\n",
    "q = q.join(ArtistCreditName, ArtistCredit.id == ArtistCreditName.artist_credit)\n",
    "q = q.join(Artist, ArtistCreditName.artist == Artist.id)\n",
    "q = q.outerjoin(Gender, Artist.gender == Gender.id)\n",
    "q = q.outerjoin(ArtistType, Artist.type == ArtistType.id)\n",
    "q = q.outerjoin(ReleaseLabel, ReleaseLabel.release == Release.id)\n",
    "q = q.outerjoin(Label, ReleaseLabel.label == Label.id)\n",
    "q = q.join(Medium, Medium.release == Release.id)\n",
    "q = q.join(CoverArt, CoverArt.release == Release.id)\n",
    "q = q.join(CoverArtType, CoverArtType.id == CoverArt.id)\n",
    "\n",
    "# Also join the results from the subqueries\n",
    "q = q.outerjoin(ReleaseDate, ReleaseDate.c.release == Release.id)\n",
    "q = q.outerjoin(Packaging, Packaging.c.release_group == Release.release_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find everything we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = q.filter(Release.language == 145, Release.script == 28) # German with latin script\n",
    "q = q.filter(Release.status == 1) # Official release\n",
    "q = q.filter(ArtistCreditName.position == 0)   # Additional info only for main Artist\n",
    "q = q.filter(Artist.id != 1) # No various artists releases\n",
    "q = q.filter(CoverArtType.type_id == 1)  # only albums that have a front cover image\n",
    "q = q.filter(Medium.position == 1)   # filter some weird albums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are only interested in one single entry per _release_group_. On PostgreSQL this can be done with a combination of a <code>DISTINCT ON &lt;COLUMN></code> and <code>ORDER BY</code> clause. In our case, we arbitrarily prefer CD releases with the lowest number of tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = q.distinct(Release.release_group)\n",
    "q = q.order_by(Release.release_group, Medium.format, Medium.track_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see, with how many albums we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6404"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q = q.filter(ArtistCredit.name == 'Die Ã„rzte')#, Release.name == 'Planet Punk')\n",
    "\n",
    "total_releases = q.count()\n",
    "total_releases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, quite a bunch.\n",
    "\n",
    "### Additional queries \n",
    "While going through all the albums, we need two additional queries to fetch the tracks and a list with all the featuring artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_q = session.query(Track, ArtistCredit.name)\n",
    "track_q = track_q.join(ArtistCredit, Track.artist_credit == ArtistCredit.id)\n",
    "track_q = track_q.join(Medium, Track.medium == Medium.id)\n",
    "track_q = track_q.filter(Medium.release == bindparam('release'))\n",
    "track_q = track_q.order_by(Medium.position, Track.position)\n",
    "\n",
    "feat_q = session.query(ArtistCreditName.name).distinct()\n",
    "feat_q = feat_q.join(ArtistCredit, ArtistCredit.id == ArtistCreditName.artist_credit)\n",
    "feat_q = feat_q.filter(ArtistCredit.artist_count > 1, ArtistCreditName.position > 1)\n",
    "feat_q = feat_q.join(Track, Track.artist_credit == ArtistCredit.id)\n",
    "feat_q = feat_q.join(Medium, Medium.id == Track.medium)\n",
    "feat_q = feat_q.filter(Medium.release == bindparam('release'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the JSON and write it to a file\n",
    "\n",
    "This takes some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 / 6404\n",
      "1000 / 6404\n",
      "1500 / 6404\n",
      "2000 / 6404\n",
      "2500 / 6404\n",
      "3000 / 6404\n",
      "3500 / 6404\n",
      "4000 / 6404\n",
      "4500 / 6404\n",
      "5000 / 6404\n",
      "5500 / 6404\n",
      "6000 / 6404\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "i = 0\n",
    "\n",
    "for (release_id, release_gid, release_name, release_group, release_type, \n",
    "     release_year, release_date, credit_name, artist_name, \n",
    "     artist_begin_year,  artist_end_year, artist_gender, artist_type, \n",
    "     packaging, label_name) in q:\n",
    "    \n",
    "    i += 1\n",
    "    if (i%500 == 0): print(i, '/', total_releases)\n",
    "\n",
    "    tracks = track_q.params(release=release_id)\n",
    "    track_list = [\n",
    "        {\n",
    "            \"gid\": track.gid,\n",
    "            \"number\": track.number,\n",
    "            \"title\": track.name,\n",
    "            \"artist\": artist_credit,\n",
    "            \"length\": track.length // 1000 if track.length else 0,\n",
    "        } for track, artist_credit in tracks\n",
    "    ]\n",
    "    \n",
    "    feats = [feat for feat in feat_q.params(release=release_id)]\n",
    "    \n",
    "    data.append({\n",
    "        \"gid\": release_gid,\n",
    "        \"album_title\" : release_name,\n",
    "        \"album_release_year\": release_year,\n",
    "        \"album_release_date\": release_date,\n",
    "        \"album_artist\": credit_name,\n",
    "        \"main_artist\": {\n",
    "            \"name\": artist_name, \n",
    "            \"gender\": artist_gender,\n",
    "            \"artist_type\": artist_type,\n",
    "            \"active_from\": artist_begin_year,\n",
    "            \"active_until\": artist_end_year,\n",
    "        },\n",
    "        \"cover_image\": \"http://coverartarchive.org/release/{}/front\".format(release_gid),\n",
    "        \"packaging\": list(packaging) if packaging else [],\n",
    "        \"label\": label_name,\n",
    "        \"release_type\": release_type,\n",
    "        \"featurings\": feats,\n",
    "        \"track_count\": len(track_list),\n",
    "        \"tracks\": track_list,\n",
    "    })\n",
    "\n",
    "json.dump(data, open(dump_filename, 'w'), sort_keys=True, \n",
    "          indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"album_artist\": \"In Extremo\",\n",
      "        \"album_release_date\": \"1999-08-30\",\n",
      "        \"album_release_year\": 1999,\n",
      "        \"album_title\": \"Verehrt und angespien\",\n",
      "        \"cover_image\": \"http://coverartarchive.org/release/3ebfa0e4-0f05-4719-a8ed-d4bee5683e61/front\",\n",
      "        \"featurings\": [],\n",
      "        \"gid\": \"3ebfa0e4-0f05-4719-a8ed-d4bee5683e61\",\n",
      "        \"label\": \"Mercury Records\",\n",
      "        \"main_artist\": {\n",
      "            \"active_from\": 1995,\n",
      "            \"active_until\": null,\n",
      "            \"artist_type\": \"Group\",\n",
      "            \"gender\": null,\n",
      "            \"name\": \"In Extremo\"\n",
      "        },\n",
      "        \"packaging\": [\n",
      "            \"Digipak\",\n",
      "            \"Jewel Case\"\n",
      "        ],\n",
      "        \"release_type\": \"Album\",\n",
      "        \"track_count\": 13,\n",
      "        \"tracks\": [\n",
      "            {\n",
      "                \"artist\": \"In Extremo\",\n",
      "                \"gid\": \"7b6fb6c0-9431-3073-86a1-ccc56428cda9\",\n",
      "                \"length\": 268,\n",
      "                \"number\": \"1\",\n",
      "                \"title\": \"Merseburger Zauberspr\\u00fcche\"\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(''.join(open(dump_filename).readlines()[:30]))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Lyrics with PyLyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 6404\n",
      "10 / 6404\n",
      "20 / 6404\n",
      "30 / 6404\n",
      "40 / 6404\n",
      "50 / 6404\n",
      "60 / 6404\n",
      "70 / 6404\n",
      "80 / 6404\n",
      "90 / 6404\n",
      "100 / 6404\n",
      "110 / 6404\n",
      "120 / 6404\n",
      "130 / 6404\n",
      "140 / 6404\n",
      "150 / 6404\n",
      "160 / 6404\n",
      "170 / 6404\n",
      "180 / 6404\n",
      "190 / 6404\n",
      "200 / 6404\n",
      "210 / 6404\n",
      "220 / 6404\n",
      "230 / 6404\n",
      "240 / 6404\n",
      "250 / 6404\n",
      "260 / 6404\n",
      "270 / 6404\n",
      "280 / 6404\n",
      "290 / 6404\n",
      "300 / 6404\n",
      "310 / 6404\n",
      "320 / 6404\n",
      "330 / 6404\n",
      "340 / 6404\n",
      "350 / 6404\n",
      "360 / 6404\n",
      "370 / 6404\n",
      "380 / 6404\n",
      "390 / 6404\n",
      "400 / 6404\n",
      "410 / 6404\n",
      "420 / 6404\n",
      "430 / 6404\n",
      "440 / 6404\n",
      "450 / 6404\n",
      "460 / 6404\n",
      "470 / 6404\n",
      "480 / 6404\n",
      "490 / 6404\n",
      "500 / 6404\n",
      "510 / 6404\n",
      "520 / 6404\n",
      "530 / 6404\n",
      "540 / 6404\n",
      "550 / 6404\n",
      "560 / 6404\n",
      "570 / 6404\n",
      "580 / 6404\n",
      "590 / 6404\n",
      "600 / 6404\n",
      "610 / 6404\n",
      "620 / 6404\n",
      "630 / 6404\n",
      "640 / 6404\n",
      "650 / 6404\n",
      "660 / 6404\n",
      "670 / 6404\n",
      "680 / 6404\n",
      "690 / 6404\n",
      "700 / 6404\n",
      "710 / 6404\n",
      "720 / 6404\n",
      "730 / 6404\n",
      "740 / 6404\n",
      "750 / 6404\n",
      "760 / 6404\n",
      "770 / 6404\n"
     ]
    }
   ],
   "source": [
    "for i, album in enumerate(json.load(open(dump_filename))):\n",
    "    if (i % 10 == 0): print(i, '/', total_releases)\n",
    "    path = os.path.join(lyrics_dir, album['gid'])\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    for track in album['tracks']:\n",
    "        lyrics_file = os.path.join(path, track['gid'])\n",
    "        if not os.path.exists(lyrics_file):\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    lyrics = PyLyrics.PyLyrics.getLyrics(track['artist'], track['title'])\n",
    "            except ValueError:\n",
    "                lyrics = ''\n",
    "            open(lyrics_file, 'w').write(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Lyrics in to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = json.load(open(dump_filename))\n",
    "    \n",
    "for i, album in enumerate(data):\n",
    "    if album:\n",
    "        dir_path = os.path.join(lyrics_dir, album['gid'])\n",
    "        if os.path.isdir(dir_path):\n",
    "            for track in album['tracks']:\n",
    "                file_path = os.path.join(dir_path, track['gid'])\n",
    "                if os.path.exists(file_path):\n",
    "                    with open(file_path) as lf:\n",
    "                        track['lyrics'] = lf.read()\n",
    "        \n",
    "with open(final_filename, 'w') as out_file:\n",
    "    json.dump(data, out_file, sort_keys=True, indent=4, separators=(',', ': '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
